import streamlit as st
import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import joblib
from sklearn.preprocessing import MinMaxScaler
import PyPDF2
from io import BytesIO
from datetime import datetime
from pathlib import Path
import plotly.express as px

# --- CONFIGURA√á√ÉO INICIAL E CONSTANTES ---

MAPA_NIVEL_PROFISSIONAL = {
    'aprendiz': 1, 'trainee': 2, 'auxiliar': 3, 'assistente': 4,
    't√©cnico de n√≠vel m√©dio': 5, 'j√∫nior': 5.5, 'analista': 6,
    'pleno': 7, 'supervisor': 7, 'l√≠der': 7.5, 's√™nior': 8,
    'especialista': 9, 'coordenador': 9, 'gerente': 10
}

# --- FUN√á√ïES DE SETUP E CARREGAMENTO ---

@st.cache_resource
def setup_nltk():
    """Verifica e baixa os dados necess√°rios do NLTK de forma segura."""
    try:
        nltk.data.find('corpora/stopwords')
    except LookupError:
        nltk.download('stopwords')
    try:
        nltk.data.find('tokenizers/punkt')
    except LookupError:
        nltk.download('punkt')
    return set(stopwords.words('portuguese'))

STOPWORDS_PT = setup_nltk()

@st.cache_resource
def load_models():
    """Carrega os modelos de forma robusta, evitando erros de caminho."""
    try:
        base_dir = Path(__file__).resolve().parent
        model = joblib.load(base_dir / 'modelo_rf_final.pkl')
        scaler = joblib.load(base_dir / 'scaler_final.pkl')
        vectorizer = joblib.load(base_dir / 'tfidf_vectorizer.pkl')
        return model, scaler, vectorizer
    except FileNotFoundError as e:
        st.error(f"Erro de Ficheiro N√£o Encontrado: '{e.filename}'.")
        st.warning("Certifique-se de que os ficheiros de modelo (.pkl) est√£o na mesma pasta que a aplica√ß√£o.")
        st.stop()
    except Exception as e:
        st.error(f"Erro ao carregar os modelos: {str(e)}")
        st.stop()

# --- FUN√á√ïES DE PROCESSAMENTO DE DADOS ---

def extract_text_from_pdf(uploaded_file: BytesIO) -> str:
    """Extrai texto de um ficheiro PDF em mem√≥ria."""
    try:
        pdf_reader = PyPDF2.PdfReader(uploaded_file)
        text = "".join(page.extract_text() or "" for page in pdf_reader.pages)
        return text
    except Exception as e:
        st.error(f"Erro ao ler o ficheiro PDF: {str(e)}")
        return ""

def preprocessar_texto(texto: str) -> str:
    """Limpa e pr√©-processa o texto para an√°lise."""
    if not isinstance(texto, str):
        return ""
    texto = texto.lower()
    texto = re.sub(r'[^\w\s]', ' ', texto)
    texto = re.sub(r'\s+', ' ', texto).strip()
    palavras = [palavra for palavra in texto.split() if palavra not in STOPWORDS_PT and len(palavra) >= 3]
    return ' '.join(palavras)

def extrair_competencias(texto_requisitos: str) -> set:
    """Extrai compet√™ncias da caixa de texto, tratando termos com m√∫ltiplas palavras."""
    if not texto_requisitos:
        return set()
    return {comp.strip().lower() for comp in texto_requisitos.split(',') if comp.strip()}

def mapear_nivel(texto_cv: str, mapa: dict) -> int:
    """Fun√ß√£o gen√©rica para encontrar o maior n√≠vel de um mapa num texto."""
    if not texto_cv or pd.isna(texto_cv):
        return 0
    texto_lower = str(texto_cv).lower()
    niveis_encontrados = [valor for chave, valor in mapa.items() if chave in texto_lower]
    return max(niveis_encontrados) if niveis_encontrados else 0

def calcular_status(score: float) -> tuple[str, str]:
    """Calcula o status e a cor correspondente com base no score."""
    if score >= 0.6:
        return "‚úÖ Recomendado", "green"
    elif score >= 0.4:
        return "üü® Potencial", "orange"
    else:
        return "‚ùå Baixa Ader√™ncia", "red"

# --- FUN√á√ïES DE RENDERIZA√á√ÉO DE P√ÅGINAS E COMPONENTES ---

def render_sidebar():
    """Renderiza a barra lateral da aplica√ß√£o."""
    with st.sidebar:
        st.image("https://storage.googleapis.com/gemini-prod-us-west1-423907-8353/images/7a0402.png-ce9c0648-a0b8-45b7-8385-3dd46fef44e4", use_container_width=True)
        st.header("‚ÑπÔ∏è Sobre o Sistema")
        st.info("""
        Esta aplica√ß√£o utiliza Machine Learning para otimizar a triagem de curr√≠culos,
        comparando-os com os requisitos de uma vaga.
        """)
        st.divider()
        st.markdown(f"**Vers√£o:** 12.0 | {datetime.now().strftime('%d/%m/%Y')}")

def render_results(df_resultados, detalhes_candidatos, job_title):
    """Renderiza os resultados da an√°lise em m√∫ltiplas abas."""
    st.success(f"‚úÖ An√°lise conclu√≠da para {len(df_resultados)} candidatos para a vaga de **{job_title}**!")
    
    tab_dashboard, tab_ranking, tab_individual, tab_export = st.tabs(["üèÜ Dashboard", "üìä Ranking Geral", "üë§ An√°lise Individual", "üì§ Exportar"])
    
    with tab_dashboard:
        st.header("Dashboard da An√°lise")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Total de Candidatos Analisados", len(df_resultados))
            melhor_score = df_resultados['Score Combinado'].max()
            st.metric("Melhor Score Encontrado", f"{melhor_score:.1%}")
        with col2:
            status_counts = df_resultados['Status'].value_counts().rename_axis('Status').reset_index(name='Contagem')
            st.dataframe(status_counts, use_container_width=True)
            
        st.subheader("Distribui√ß√£o de Status dos Candidatos")
        
        # Mapeamento de cores atualizado para o gr√°fico
        color_map = {
            "‚úÖ Recomendado": "green",
            "üü® Potencial": "orange",
            "‚ùå Baixa Ader√™ncia": "red"
        }
        
        fig = px.bar(
            status_counts, 
            x='Status', 
            y='Contagem',
            color='Status',
            color_discrete_map=color_map,
            text='Contagem'
        )
        fig.update_layout(xaxis_title="Status", yaxis_title="N√∫mero de Candidatos")
        st.plotly_chart(fig, use_container_width=True)


    with tab_ranking:
        st.header("Vis√£o Geral dos Candidatos")
        
        col_filter1, col_filter2 = st.columns([3, 1])
        
        with col_filter1:
            status_options = df_resultados['Status'].unique().tolist()
            status_selecionado = st.multiselect(
                "Filtrar por Status:",
                options=status_options,
                default=status_options,
                key='ranking_status_filter'
            )
        
        with col_filter2:
            st.write("") 
            st.write("")
            top_10_apto = st.checkbox("Ver Top 10 Recomendados", key='ranking_top10_filter')

        # L√≥gica de filtragem atualizada
        df_filtrado_ranking = df_resultados.copy()
        if top_10_apto:
            df_filtrado_ranking = df_filtrado_ranking[df_filtrado_ranking['Status'] == "‚úÖ Recomendado"].head(10)
        elif status_selecionado:
            df_filtrado_ranking = df_filtrado_ranking[df_filtrado_ranking['Status'].isin(status_selecionado)]
        else:
            df_filtrado_ranking = pd.DataFrame(columns=df_resultados.columns)

        st.dataframe(
            df_filtrado_ranking[["ID", "Nome", "Score Combinado", "Status", "Probabilidade", "Match"]],
            column_config={
                "Score Combinado": st.column_config.ProgressColumn("Score", format="%.1f%%", min_value=0, max_value=1),
                "Probabilidade": st.column_config.ProgressColumn("Prob.", format="%.1f%%", min_value=0, max_value=1),
                "Match": st.column_config.ProgressColumn("Match", format="%.1f%%", min_value=0, max_value=1),
            },
            hide_index=True,
            use_container_width=True
        )

    with tab_individual:
        st.header("An√°lise Detalhada por Candidato")

        col_ind_filter1, col_ind_filter2 = st.columns([3, 1])
        with col_ind_filter1:
            status_options_ind = df_resultados['Status'].unique().tolist()
            status_selecionado_ind = st.multiselect(
                "Filtrar por Status:",
                options=status_options_ind,
                default=status_options_ind,
                key='individual_status_filter'
            )
        with col_ind_filter2:
            st.write("")
            st.write("")
            top_10_apto_ind = st.checkbox("Ver Top 10 Recomendados", key='individual_top10_filter')

        df_filtrado_individual = df_resultados.copy()
        if top_10_apto_ind:
            df_filtrado_individual = df_filtrado_individual[df_filtrado_individual['Status'] == "‚úÖ Recomendado"].head(10)
        elif status_selecionado_ind:
            df_filtrado_individual = df_filtrado_individual[df_filtrado_individual['Status'].isin(status_selecionado_ind)]
        else:
            df_filtrado_individual = pd.DataFrame(columns=df_resultados.columns)

        ids_para_exibir = df_filtrado_individual['ID'].tolist()
        detalhes_filtrados = [d for d in detalhes_candidatos if d['ID'] in ids_para_exibir]

        for detalhe in detalhes_filtrados:
            with st.container(border=True):
                score_combinado = df_resultados.loc[df_resultados['ID'] == detalhe['ID'], 'Score Combinado'].iloc[0]
                status_texto, _ = calcular_status(score_combinado)
                
                st.subheader(f"ÔøΩ {detalhe['Nome']}")
                st.write(f"**Status:** {status_texto}")
                
                st.markdown("**M√©tricas Principais:**")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Score Combinado", f"{score_combinado:.1%}")
                with col2:
                    st.metric("Probabilidade do Modelo", f"{detalhe['Probabilidade']:.1%}")
                with col3:
                    st.metric("Match de Compet√™ncias", f"{detalhe['Match']:.1%}")

                st.markdown("**Ader√™ncia aos Requisitos:**")
                col_ader1, col_ader2, col_ader3 = st.columns(3)
                with col_ader1:
                    st.metric("N√≠vel Acad√©mico", f"{detalhe['Ader√™ncia Acad√™mica']*100:.0f}%", help="100% = Atende ou supera o requisito.")
                with col_ader2:
                    st.metric("N√≠vel de Ingl√™s", f"{detalhe['Ader√™ncia Ingl√™s']*100:.0f}%", help="100% = Atende ou supera o requisito.")
                with col_ader3:
                    st.metric("N√≠vel de Espanhol", f"{detalhe['Ader√™ncia Espanhol']*100:.0f}%", help="100% = Atende ou supera o requisito.")

                col_comp1, col_comp2 = st.columns(2)
                with col_comp1:
                    st.markdown("**Compet√™ncias encontradas:**")
                    st.success(detalhe["TermosEncontrados"] or "Nenhuma compet√™ncia encontrada.", icon="‚úÖ")
                with col_comp2:
                    st.markdown("**Principais compet√™ncias em falta:**")
                    st.warning(detalhe["TermosFaltantes"] or "Nenhuma compet√™ncia em falta.", icon="‚ö†Ô∏è")
                
                st.markdown("**Trecho processado do curr√≠culo:**")
                st.text_area("Texto Analisado", value=detalhe["TextoProcessado"], height=150, disabled=True, key=f"texto_{detalhe['ID']}")
    
    with tab_export:
        st.header("Download dos Resultados da An√°lise")
        st.markdown("Fa√ßa o download dos dados da an√°lise nos formatos CSV.")
        
        with st.container(border=True):
            df_detalhes_export = pd.DataFrame(detalhes_candidatos)
            df_export_completo = pd.merge(df_resultados, df_detalhes_export, on="ID")
            
            col_exp1, col_exp2 = st.columns(2)
            with col_exp1:
                csv_resumo = df_resultados.to_csv(index=False, sep=';', decimal=',', encoding='utf-8-sig')
                st.download_button("üìä Exportar Resumo CSV", csv_resumo, f"resumo_candidatos_{job_title.replace(' ', '_')}.csv", "text/csv", use_container_width=True)
            with col_exp2:
                csv_detalhes = df_export_completo.to_csv(index=False, sep=';', decimal=',', encoding='utf-8-sig')
                st.download_button("üìù Exportar Detalhes CSV", csv_detalhes, f"detalhes_candidatos_{job_title.replace(' ', '_')}.csv", "text/csv", use_container_width=True)

def render_main_page():
    """Renderiza a p√°gina principal da ferramenta de an√°lise."""
    st.header("üéØ Ferramenta de An√°lise")
    with st.container(border=True):
        with st.form("vaga_form"):
            st.subheader("üìù Informa√ß√µes da Vaga")
            job_title = st.text_input("T√≠tulo da Vaga*", placeholder="Ex: Engenheiro de Dados S√™nior")
            job_requirements = st.text_area("Compet√™ncias T√©cnicas Requeridas*", placeholder="Ex: Python, SQL, Power BI, Machine Learning...", height=150, help="Liste as habilidades-chave (incluindo as com m√∫ltiplas palavras) separadas por v√≠rgula.")
            col1, col2 = st.columns(2)
            with col1:
                job_academic_level = st.selectbox("N√≠vel Acad√©mico Requerido*", ["Ensino M√©dio", "Ensino T√©cnico", "Ensino Superior", "P√≥s-Gradua√ß√£o", "Mestrado", "Doutorado"])
                job_english = st.selectbox("Ingl√™s Exigido*", ["Nenhum", "B√°sico", "Intermedi√°rio", "Avan√ßado", "Fluente"])
            with col2:
                job_professional_level = st.selectbox("N√≠vel Profissional*", list(MAPA_NIVEL_PROFISSIONAL.keys()))
                job_spanish = st.selectbox("Espanhol Exigido", ["Nenhum", "B√°sico", "Intermedi√°rio", "Avan√ßado", "Fluente"])
            st.subheader("üë§ Curr√≠culos para An√°lise")
            uploaded_files = st.file_uploader("Selecione os curr√≠culos em PDF*", type=["pdf"], accept_multiple_files=True)
            submitted = st.form_submit_button("üöÄ Analisar Candidatos", use_container_width=True)

    if "resultados_df" in st.session_state and not submitted:
        render_results(st.session_state.resultados_df, st.session_state.detalhes_candidatos, st.session_state.job_title)

    if submitted:
        if not all([job_title, job_requirements, uploaded_files]):
            st.error("üö® Por favor, preencha todos os campos obrigat√≥rios (*) e envie pelo menos um curr√≠culo.")
            st.stop()
        
        model, scaler, tfidf_vectorizer = load_models()
        resultados, detalhes_candidatos = [], []
        termos_vaga = extrair_competencias(job_requirements)
        req_preprocessados_tfidf = preprocessar_texto(" ".join(termos_vaga))
        mapa_academico = {"ensino m√©dio": 1, "ensino t√©cnico": 1.5, "ensino superior": 2, "p√≥s-gradua√ß√£o": 3, "mestrado": 4, "doutorado": 5}
        mapa_idioma = {"nenhum": 0, "b√°sico": 1, "intermedi√°rio": 2, "avan√ßado": 3, "fluente": 4}
        nivel_academico_vaga = mapear_nivel(job_academic_level, mapa_academico)
        nivel_ingles_vaga = mapear_nivel(job_english, mapa_idioma)
        nivel_espanhol_vaga = mapear_nivel(job_spanish, mapa_idioma)
        nivel_profissional_vaga = MAPA_NIVEL_PROFISSIONAL.get(job_professional_level, 0)
        
        for idx, uploaded_file in enumerate(uploaded_files):
            with st.spinner(f"Processando {uploaded_file.name}..."):
                cv_text_raw = extract_text_from_pdf(BytesIO(uploaded_file.getvalue()))
                if not cv_text_raw:
                    st.warning(f"N√£o foi poss√≠vel extrair texto de {uploaded_file.name}.")
                    continue
                cv_preprocessado_completo = preprocessar_texto(cv_text_raw)
                termos_encontrados = {term for term in termos_vaga if term in cv_text_raw.lower()}
                match_percent = len(termos_encontrados) / len(termos_vaga) if termos_vaga else 0
                try:
                    tfidf_matrix = tfidf_vectorizer.transform([req_preprocessados_tfidf, cv_preprocessado_completo])
                    similaridade = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
                except Exception:
                    similaridade = 0.0
                nivel_academico_candidato = mapear_nivel(cv_text_raw, mapa_academico)
                aderencia_academica = 1.0 if nivel_academico_candidato >= nivel_academico_vaga else 0.0
                nivel_ingles_candidato = mapear_nivel(cv_text_raw, mapa_idioma)
                aderencia_ingles = 1.0 if nivel_ingles_candidato >= nivel_ingles_vaga else 0.0
                nivel_espanhol_candidato = mapear_nivel(cv_text_raw, mapa_idioma)
                aderencia_espanhol = 1.0 if nivel_espanhol_candidato >= nivel_espanhol_vaga else 0.0
                
                features = np.array([[
                    match_percent, similaridade, len(termos_encontrados),
                    aderencia_academica, aderencia_ingles, aderencia_espanhol,
                    nivel_profissional_vaga / 10
                ]]).reshape(1, -1)
                
                features_scaled = scaler.transform(features)
                probabilidade = model.predict_proba(features_scaled)[0, 1]
                score_combinado = (probabilidade * 0.3) + (match_percent * 0.4) + (similaridade * 0.2) + (aderencia_academica * 0.1)
                status, _ = calcular_status(score_combinado)
                
                resultados.append({"ID": idx + 1, "Nome": uploaded_file.name, "Score Combinado": score_combinado, "Status": status, "Probabilidade": probabilidade, "Match": match_percent})
                detalhes_candidatos.append({"ID": idx + 1, "Nome": uploaded_file.name, "Probabilidade": probabilidade, "Match": match_percent, "Ader√™ncia Acad√™mica": aderencia_academica, "Ader√™ncia Ingl√™s": aderencia_ingles, "Ader√™ncia Espanhol": aderencia_espanhol, "TermosEncontrados": ", ".join(sorted(termos_encontrados)) or "Nenhum", "TermosFaltantes": ", ".join(sorted(termos_vaga - termos_encontrados)) or "Nenhum", "TextoProcessado": cv_preprocessado_completo[:500] + "..."})
        
        if resultados:
            st.session_state.resultados_df = pd.DataFrame(resultados).sort_values("Score Combinado", ascending=False)
            ids_ordenados = st.session_state.resultados_df['ID'].tolist()
            st.session_state.detalhes_candidatos = sorted(detalhes_candidatos, key=lambda x: ids_ordenados.index(x['ID']))
            st.session_state.job_title = job_title
            st.rerun()
        else:
            st.warning("Nenhum candidato p√¥de ser processado.")

def render_metrics_page():
    """Renderiza a p√°gina com a explica√ß√£o das m√©tricas de avalia√ß√£o."""
    st.title("üìä M√©tricas de Avalia√ß√£o")
    st.markdown("""
    Esta sec√ß√£o detalha como cada candidato √© avaliado, garantindo um processo transparente e baseado em dados.
    """)
    
    st.subheader("‚öñÔ∏è Peso do C√°lculo do Score Combinado")
    st.markdown("""
    O **Score Combinado** √© uma m√©dia ponderada de quatro fatores principais,
    desenhado para fornecer uma vis√£o hol√≠stica da adequa√ß√£o de um candidato.
    - **40% Match de Compet√™ncias:** A percentagem de compet√™ncias t√©cnicas requeridas na vaga que foram encontradas textualmente no curr√≠culo. √â a m√©trica com maior peso.
    - **30% Probabilidade do Modelo:** A confian√ßa do modelo de Machine Learning (de 0 a 100%) de que o candidato √© um bom "fit", com base na an√°lise conjunta de 7 caracter√≠sticas.
    - **20% Similaridade Textual:** Mede a semelhan√ßa de contexto e sem√¢ntica entre o curr√≠culo e a descri√ß√£o da vaga, usando a t√©cnica TF-IDF.
    - **10% Ader√™ncia Acad√©mica:** Verifica se o n√≠vel de forma√ß√£o do candidato atende ao requisito m√≠nimo da vaga.
    """)

    st.subheader("Como Interpretar as M√©tricas")
    st.markdown("""
    | M√©trica             | Descri√ß√£o                               | Como Interpretar                                                                    |
    |---------------------|-----------------------------------------|-------------------------------------------------------------------------------------|
    | **Score Combinado** | Avalia√ß√£o final ponderada (0-100%).     | - **‚úÖ 60%:** Apto- **üü® 40-59%:** Em an√°lise- **‚ùå <40%:** N√£o apto        |
    | **Match** | % de compet√™ncias encontradas.          | Quanto maior, mais requisitos t√©cnicos o candidato atende.                          |
    | **Probabilidade** | Previs√£o do modelo (0-100%).            | A confian√ßa do modelo de que o perfil do candidato √© adequado para a vaga.          |
    | **Ader√™ncia** | Adequa√ß√£o aos requisitos.               | Mostra se o candidato atende aos requisitos de forma√ß√£o e idiomas.                  |
    """)

def render_storytelling_page():
    """Renderiza a p√°gina de Storytelling do projeto."""
    st.title("üìñ Storytelling do Projeto")
    st.markdown("""
    ### O Problema
    No din√¢mico mercado de trabalho atual, recrutadores enfrentam um desafio monumental: analisar centenas, por vezes milhares, de curr√≠culos para cada vaga. Este processo manual n√£o √© apenas demorado e repetitivo, mas tamb√©m est√° sujeito a vieses inconscientes que podem levar √† exclus√£o de talentos promissores. Encontrar o candidato ideal numa pilha de documentos √© como procurar uma agulha num palheiro.
    ### A Solu√ß√£o
    Esta ferramenta nasceu para revolucionar a triagem inicial de candidatos. Utilizando o poder do **Processamento de Linguagem Natural (NLP)** e de modelos de **Machine Learning**, a nossa aplica√ß√£o transforma o processo de recrutamento. Ela l√™ e interpreta os curr√≠culos, compara-os de forma inteligente com os requisitos da vaga e gera um **score de compatibilidade** objetivo e baseado em dados.
    ### O Impacto
    O nosso objetivo √© claro: **libertar o tempo e o talento dos recrutadores**. Ao automatizar a triagem, permitimos que os profissionais de RH se foquem no que realmente importa: as intera√ß√µes humanas, as entrevistas estrat√©gicas e a constru√ß√£o de rela√ß√µes com os melhores talentos. A ferramenta n√£o substitui o recrutador, mas sim potencia as suas capacidades, oferecendo uma an√°lise objetiva que ajuda a construir equipas mais fortes e diversificadas.
    """)

def render_tech_page():
    """Renderiza a p√°gina com as tecnologias utilizadas no projeto."""
    st.title("üõ†Ô∏è Tecnologias Utilizadas")
    st.markdown("Esta aplica√ß√£o foi constru√≠da com um conjunto de tecnologias modernas e robustas do ecossistema Python, focadas em ci√™ncia de dados e desenvolvimento web.")
    
    st.subheader("Interface e Visualiza√ß√£o")
    st.markdown("- **Streamlit:** Framework principal para a cria√ß√£o da interface web interativa.")
    
    st.subheader("An√°lise e Manipula√ß√£o de Dados")
    st.markdown("- **Pandas:** Utilizado para a estrutura√ß√£o e manipula√ß√£o eficiente dos dados dos resultados.")
    st.markdown("- **NumPy:** Essencial para c√°lculos num√©ricos e a cria√ß√£o das 'features' para o modelo.")
    
    st.subheader("Machine Learning e NLP")
    st.markdown("- **Scikit-learn:** A biblioteca central para o nosso modelo de Machine Learning (`RandomForestClassifier`), pr√©-processamento (`MinMaxScaler`) e c√°lculo de similaridade (`TfidfVectorizer`, `cosine_similarity`).")
    st.markdown("- **NLTK (Natural Language Toolkit):** Usado para o processamento de texto, como a remo√ß√£o de 'stopwords', fundamental para a an√°lise de compet√™ncias.")
    
    st.subheader("Processamento de Ficheiros")
    st.markdown("- **PyPDF2:** Biblioteca que permite a extra√ß√£o de texto diretamente dos ficheiros de curr√≠culo em formato PDF.")

# --- FUN√á√ÉO PRINCIPAL E ROTEADOR DE P√ÅGINAS ---

def main():
    """Fun√ß√£o principal que define a estrutura da aplica√ß√£o e a navega√ß√£o."""
    st.set_page_config(page_title="Sistema de Triagem de CVs", layout="wide", initial_sidebar_state="expanded")
    
    render_sidebar()
    st.title("Sistema Inteligente de Triagem de Curr√≠culos")
    
    # Navega√ß√£o por Abas no Topo da P√°gina
    tab_main, tab_metrics, tab_story, tab_tech = st.tabs(["An√°lise de Curr√≠culos", "M√©tricas de Avalia√ß√£o", "Storytelling do Projeto", "Tecnologias Utilizadas"])

    with tab_main:
        render_main_page()
    
    with tab_metrics:
        render_metrics_page()
    
    with tab_story:
        render_storytelling_page()
        
    with tab_tech:
        render_tech_page()

if __name__ == "__main__":
    main()
