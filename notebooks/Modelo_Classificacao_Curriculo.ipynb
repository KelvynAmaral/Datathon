{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3378e38",
   "metadata": {},
   "source": [
    "# Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "006a4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import json\n",
    "#Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Import numpy\n",
    "import numpy as np\n",
    "\n",
    "#Import sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Import regex for text processing\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f72b2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3150b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caminho para o Google Drive\n",
    "file_Prospects  = '1Y5eePChAUU3Lv581ms-OEfvDQdOhFSqZ'\n",
    "file_Applicants = '1M5mmqRf6XmlZU18u3a1Qv9WLLSAe64pP'\n",
    "file_Vagas      = '1bG8_reZXL2fkswXvUQoCIvm9UUSPOaGW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6db64001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baixar os arquivos do Google Drive\n",
    "# # Certifique-se de que o gdown est√° instalado: pip install gdown\n",
    "# gdown.download(f'https://drive.google.com/uc?export=download&id={file_Prospects}', 'prospects.json', quiet=False)\n",
    "# gdown.download(f'https://drive.google.com/uc?export=download&id={file_Applicants}', 'applicants.json', quiet=False)\n",
    "# gdown.download(f'https://drive.google.com/uc?export=download&id={file_Vagas}', 'vagas.json', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "764150f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fun√ß√£o para carregar arquivos JSON com tratamento de erros\n",
    "def load_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Arquivo n√£o encontrado: {file_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"‚ùå Erro ao decodificar JSON no arquivo: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro inesperado no arquivo {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27eccff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Fun√ß√£o para remover barras invertidas (\\) de strings, listas e dicion√°rios\n",
    "def remove_backslashes_from_data(data):\n",
    "    if isinstance(data, str):\n",
    "        return data.replace(\"\\\\\", \"\")  # Corrigido: remover barras invertidas\n",
    "    elif isinstance(data, dict):\n",
    "        return {key: remove_backslashes_from_data(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [remove_backslashes_from_data(item) for item in data]\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1ff4ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_prospect</th>\n",
       "      <th>titulo</th>\n",
       "      <th>modalidade</th>\n",
       "      <th>nome_candidato</th>\n",
       "      <th>codigo_candidato</th>\n",
       "      <th>situacao_candidado</th>\n",
       "      <th>data_candidatura</th>\n",
       "      <th>ultima_atualizacao</th>\n",
       "      <th>comentario</th>\n",
       "      <th>recrutador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4530</td>\n",
       "      <td>CONSULTOR CONTROL M</td>\n",
       "      <td></td>\n",
       "      <td>Jos√© Vieira</td>\n",
       "      <td>25632</td>\n",
       "      <td>Encaminhado ao Requisitante</td>\n",
       "      <td>25-03-2021</td>\n",
       "      <td>25-03-2021</td>\n",
       "      <td>Encaminhado para  - PJ R$ 72,00/hora</td>\n",
       "      <td>Ana L√≠via Moreira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4530</td>\n",
       "      <td>CONSULTOR CONTROL M</td>\n",
       "      <td></td>\n",
       "      <td>Srta. Isabela Cavalcante</td>\n",
       "      <td>25529</td>\n",
       "      <td>Encaminhado ao Requisitante</td>\n",
       "      <td>22-03-2021</td>\n",
       "      <td>23-03-2021</td>\n",
       "      <td>encaminhado para  - R$ 6.000,00 ‚Äì CLT Full , n...</td>\n",
       "      <td>Ana L√≠via Moreira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4531</td>\n",
       "      <td>2021-2607395-PeopleSoft Application Engine-Dom...</td>\n",
       "      <td></td>\n",
       "      <td>Sra. Yasmin Fernandes</td>\n",
       "      <td>25364</td>\n",
       "      <td>Contratado pela Decision</td>\n",
       "      <td>17-03-2021</td>\n",
       "      <td>12-04-2021</td>\n",
       "      <td>Data de Inicio: 12/04/2021</td>\n",
       "      <td>Juliana Cassiano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4531</td>\n",
       "      <td>2021-2607395-PeopleSoft Application Engine-Dom...</td>\n",
       "      <td></td>\n",
       "      <td>Alexia Barbosa</td>\n",
       "      <td>25360</td>\n",
       "      <td>Encaminhado ao Requisitante</td>\n",
       "      <td>17-03-2021</td>\n",
       "      <td>17-03-2021</td>\n",
       "      <td></td>\n",
       "      <td>Juliana Cassiano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4533</td>\n",
       "      <td>2021-2605708-Microfocus Application Life Cycle...</td>\n",
       "      <td></td>\n",
       "      <td>Arthur Almeida</td>\n",
       "      <td>26338</td>\n",
       "      <td>Contratado pela Decision</td>\n",
       "      <td>29-04-2021</td>\n",
       "      <td>18-05-2021</td>\n",
       "      <td></td>\n",
       "      <td>Stella Vieira</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_prospect                                             titulo modalidade  \\\n",
       "0        4530                                CONSULTOR CONTROL M              \n",
       "1        4530                                CONSULTOR CONTROL M              \n",
       "2        4531  2021-2607395-PeopleSoft Application Engine-Dom...              \n",
       "3        4531  2021-2607395-PeopleSoft Application Engine-Dom...              \n",
       "4        4533  2021-2605708-Microfocus Application Life Cycle...              \n",
       "\n",
       "             nome_candidato codigo_candidato           situacao_candidado  \\\n",
       "0               Jos√© Vieira            25632  Encaminhado ao Requisitante   \n",
       "1  Srta. Isabela Cavalcante            25529  Encaminhado ao Requisitante   \n",
       "2     Sra. Yasmin Fernandes            25364     Contratado pela Decision   \n",
       "3            Alexia Barbosa            25360  Encaminhado ao Requisitante   \n",
       "4            Arthur Almeida            26338     Contratado pela Decision   \n",
       "\n",
       "  data_candidatura ultima_atualizacao  \\\n",
       "0       25-03-2021         25-03-2021   \n",
       "1       22-03-2021         23-03-2021   \n",
       "2       17-03-2021         12-04-2021   \n",
       "3       17-03-2021         17-03-2021   \n",
       "4       29-04-2021         18-05-2021   \n",
       "\n",
       "                                          comentario         recrutador  \n",
       "0               Encaminhado para  - PJ R$ 72,00/hora  Ana L√≠via Moreira  \n",
       "1  encaminhado para  - R$ 6.000,00 ‚Äì CLT Full , n...  Ana L√≠via Moreira  \n",
       "2                         Data de Inicio: 12/04/2021   Juliana Cassiano  \n",
       "3                                                      Juliana Cassiano  \n",
       "4                                                         Stella Vieira  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚úÖ Fun√ß√£o para carregar JSON com seguran√ßa\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# ‚úÖ Fun√ß√£o gen√©rica para flatten de JSONs\n",
    "def flatten_json(data, id_name):\n",
    "    records = []\n",
    "    for prof_id, profile_info in data.items():\n",
    "        record = {id_name: prof_id}\n",
    "        for section_name, section_data in profile_info.items():\n",
    "            if isinstance(section_data, dict):\n",
    "                for key, value in section_data.items():\n",
    "                    record[f\"{section_name}__{key}\"] = value\n",
    "            else:\n",
    "                record[section_name] = section_data\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# ‚úÖ Carregar os arquivos JSON\n",
    "data_Prospects = load_json('prospects.json')\n",
    "data_Applicants = load_json('applicants.json')\n",
    "data_Vagas = load_json('vagas.json')\n",
    "\n",
    "# ‚úÖ Processar Prospects (estrutura especial por ter lista de candidatos)\n",
    "prospect_records = []\n",
    "for prof_id, profile_info in data_Prospects.items():\n",
    "    titulo = profile_info.get(\"titulo\")\n",
    "    modalidade = profile_info.get(\"modalidade\")\n",
    "\n",
    "    for prospect in profile_info.get(\"prospects\", []):\n",
    "        record = {\n",
    "            \"id_prospect\": prof_id,\n",
    "            \"titulo\": titulo,\n",
    "            \"modalidade\": modalidade,\n",
    "            \"nome_candidato\": prospect.get(\"nome\"),\n",
    "            \"codigo_candidato\": prospect.get(\"codigo\"),\n",
    "            \"situacao_candidado\": prospect.get(\"situacao_candidado\"),\n",
    "            \"data_candidatura\": prospect.get(\"data_candidatura\"),\n",
    "            \"ultima_atualizacao\": prospect.get(\"ultima_atualizacao\"),\n",
    "            \"comentario\": prospect.get(\"comentario\"),\n",
    "            \"recrutador\": prospect.get(\"recrutador\")\n",
    "        }\n",
    "        prospect_records.append(record)\n",
    "\n",
    "df_Prospects = pd.DataFrame(prospect_records)\n",
    "\n",
    "# ‚úÖ Processar Applicants\n",
    "df_Applicants = flatten_json(data_Applicants, id_name=\"id_applicant\")\n",
    "\n",
    "# ‚úÖ Processar Vagas\n",
    "df_Vagas = flatten_json(data_Vagas, id_name=\"id_vaga\")\n",
    "\n",
    "# ‚úÖ Exemplo de visualiza√ß√£o r√°pida\n",
    "df_Prospects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e140f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluindo colunas modalidade e comentario\n",
    "df_Prospects.drop('modalidade',axis=1,inplace=True)\n",
    "df_Prospects.drop('comentario',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17a5154d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_applicant', 'infos_basicas__telefone',\n",
       "       'infos_basicas__objetivo_profissional', 'infos_basicas__data_criacao',\n",
       "       'infos_basicas__inserido_por', 'infos_basicas__email',\n",
       "       'infos_basicas__local', 'infos_basicas__sabendo_de_nos_por',\n",
       "       'infos_basicas__data_atualizacao', 'infos_basicas__codigo_profissional',\n",
       "       'infos_basicas__nome', 'informacoes_pessoais__data_aceite',\n",
       "       'informacoes_pessoais__nome', 'informacoes_pessoais__fonte_indicacao',\n",
       "       'informacoes_pessoais__email', 'informacoes_pessoais__data_nascimento',\n",
       "       'informacoes_pessoais__telefone_celular', 'informacoes_pessoais__sexo',\n",
       "       'informacoes_pessoais__estado_civil', 'informacoes_pessoais__pcd',\n",
       "       'informacoes_pessoais__endereco',\n",
       "       'informacoes_profissionais__titulo_profissional',\n",
       "       'informacoes_profissionais__area_atuacao',\n",
       "       'informacoes_profissionais__conhecimentos_tecnicos',\n",
       "       'informacoes_profissionais__remuneracao',\n",
       "       'formacao_e_idiomas__nivel_academico',\n",
       "       'formacao_e_idiomas__nivel_ingles',\n",
       "       'formacao_e_idiomas__nivel_espanhol',\n",
       "       'formacao_e_idiomas__outro_idioma', 'cv_pt',\n",
       "       'formacao_e_idiomas__cursos', 'formacao_e_idiomas__ano_conclusao',\n",
       "       'informacoes_pessoais__download_cv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar valores nulos e vazios em cada coluna\n",
    "empty_counts = (df_Applicants.isnull() | (df_Applicants == '')).sum()\n",
    "\n",
    "# Indentificar colunas com mais de 40.000 valores vazios\n",
    "cols_to_drop = empty_counts[empty_counts > 40000].index\n",
    "\n",
    "# dropar as colunas com mais de 40.000 valores vazios\n",
    "df_Applicants.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "df_Applicants.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92b0701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir nulos disfar√ßados por NaN\n",
    "df_Applicants['formacao_e_idiomas__nivel_academico'] = df_Applicants['formacao_e_idiomas__nivel_academico'].replace(\n",
    "    ['', ' ', 'NULL', 'N/A', 'NA', 'None'], pd.NA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f934ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_vaga', 'informacoes_basicas__data_requicisao',\n",
       "       'informacoes_basicas__limite_esperado_para_contratacao',\n",
       "       'informacoes_basicas__titulo_vaga', 'informacoes_basicas__vaga_sap',\n",
       "       'informacoes_basicas__cliente',\n",
       "       'informacoes_basicas__solicitante_cliente',\n",
       "       'informacoes_basicas__empresa_divisao',\n",
       "       'informacoes_basicas__requisitante',\n",
       "       'informacoes_basicas__analista_responsavel',\n",
       "       'informacoes_basicas__tipo_contratacao',\n",
       "       'informacoes_basicas__prazo_contratacao',\n",
       "       'informacoes_basicas__objetivo_vaga',\n",
       "       'informacoes_basicas__prioridade_vaga',\n",
       "       'informacoes_basicas__origem_vaga',\n",
       "       'informacoes_basicas__superior_imediato', 'perfil_vaga__pais',\n",
       "       'perfil_vaga__estado', 'perfil_vaga__cidade', 'perfil_vaga__bairro',\n",
       "       'perfil_vaga__regiao', 'perfil_vaga__local_trabalho',\n",
       "       'perfil_vaga__vaga_especifica_para_pcd', 'perfil_vaga__faixa_etaria',\n",
       "       'perfil_vaga__nivel profissional', 'perfil_vaga__nivel_academico',\n",
       "       'perfil_vaga__nivel_ingles', 'perfil_vaga__nivel_espanhol',\n",
       "       'perfil_vaga__areas_atuacao', 'perfil_vaga__principais_atividades',\n",
       "       'perfil_vaga__competencia_tecnicas_e_comportamentais',\n",
       "       'perfil_vaga__demais_observacoes', 'perfil_vaga__viagens_requeridas',\n",
       "       'perfil_vaga__equipamentos_necessarios', 'beneficios__valor_venda',\n",
       "       'beneficios__valor_compra_1', 'informacoes_basicas__data_inicial',\n",
       "       'informacoes_basicas__data_final',\n",
       "       'perfil_vaga__habilidades_comportamentais_necessarias'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar valores nulos e vazios em cada coluna\n",
    "empty_counts = (df_Vagas.isnull() | (df_Vagas == '')).sum()\n",
    "\n",
    "# Identificar colunas com mais de 13.000 valores vazios\n",
    "cols_to_drop = empty_counts[empty_counts > 13000].index\n",
    "\n",
    "# Excluir as colunas com mais de 13.000 valores vazios\n",
    "df_Vagas.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "df_Vagas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ff2cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge: Applicants + Prospects\n",
    "df = df_Prospects.merge(df_Applicants, left_on='codigo_candidato', right_on='id_applicant', how='left')\n",
    "\n",
    "# Merge: Com as Vagas\n",
    "df = df.merge(df_Vagas, left_on='id_prospect', right_on='id_vaga', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a727e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configurar para mostrar todas as colunas\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# # Configurar para mostrar todas as linhas\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91c9e914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " '√†',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " '√†s',\n",
       " 'at√©',\n",
       " 'com',\n",
       " 'como',\n",
       " 'da',\n",
       " 'das',\n",
       " 'de',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele',\n",
       " 'deles',\n",
       " 'depois',\n",
       " 'do',\n",
       " 'dos',\n",
       " 'e',\n",
       " '√©',\n",
       " 'ela',\n",
       " 'elas',\n",
       " 'ele',\n",
       " 'eles',\n",
       " 'em',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'eram',\n",
       " '√©ramos',\n",
       " 'essa',\n",
       " 'essas',\n",
       " 'esse',\n",
       " 'esses',\n",
       " 'esta',\n",
       " 'est√°',\n",
       " 'estamos',\n",
       " 'est√£o',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'estava',\n",
       " 'estavam',\n",
       " 'est√°vamos',\n",
       " 'este',\n",
       " 'esteja',\n",
       " 'estejam',\n",
       " 'estejamos',\n",
       " 'estes',\n",
       " 'esteve',\n",
       " 'estive',\n",
       " 'estivemos',\n",
       " 'estiver',\n",
       " 'estivera',\n",
       " 'estiveram',\n",
       " 'estiv√©ramos',\n",
       " 'estiverem',\n",
       " 'estivermos',\n",
       " 'estivesse',\n",
       " 'estivessem',\n",
       " 'estiv√©ssemos',\n",
       " 'estou',\n",
       " 'eu',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'for',\n",
       " 'fora',\n",
       " 'foram',\n",
       " 'f√¥ramos',\n",
       " 'forem',\n",
       " 'formos',\n",
       " 'fosse',\n",
       " 'fossem',\n",
       " 'f√¥ssemos',\n",
       " 'fui',\n",
       " 'h√°',\n",
       " 'haja',\n",
       " 'hajam',\n",
       " 'hajamos',\n",
       " 'h√£o',\n",
       " 'havemos',\n",
       " 'haver',\n",
       " 'hei',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houver',\n",
       " 'houvera',\n",
       " 'houver√°',\n",
       " 'houveram',\n",
       " 'houv√©ramos',\n",
       " 'houver√£o',\n",
       " 'houverei',\n",
       " 'houverem',\n",
       " 'houveremos',\n",
       " 'houveria',\n",
       " 'houveriam',\n",
       " 'houver√≠amos',\n",
       " 'houvermos',\n",
       " 'houvesse',\n",
       " 'houvessem',\n",
       " 'houv√©ssemos',\n",
       " 'isso',\n",
       " 'isto',\n",
       " 'j√°',\n",
       " 'lhe',\n",
       " 'lhes',\n",
       " 'mais',\n",
       " 'mas',\n",
       " 'me',\n",
       " 'mesmo',\n",
       " 'meu',\n",
       " 'meus',\n",
       " 'minha',\n",
       " 'minhas',\n",
       " 'muito',\n",
       " 'na',\n",
       " 'n√£o',\n",
       " 'nas',\n",
       " 'nem',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'n√≥s',\n",
       " 'nossa',\n",
       " 'nossas',\n",
       " 'nosso',\n",
       " 'nossos',\n",
       " 'num',\n",
       " 'numa',\n",
       " 'o',\n",
       " 'os',\n",
       " 'ou',\n",
       " 'para',\n",
       " 'pela',\n",
       " 'pelas',\n",
       " 'pelo',\n",
       " 'pelos',\n",
       " 'por',\n",
       " 'qual',\n",
       " 'quando',\n",
       " 'que',\n",
       " 'quem',\n",
       " 's√£o',\n",
       " 'se',\n",
       " 'seja',\n",
       " 'sejam',\n",
       " 'sejamos',\n",
       " 'sem',\n",
       " 'ser',\n",
       " 'ser√°',\n",
       " 'ser√£o',\n",
       " 'serei',\n",
       " 'seremos',\n",
       " 'seria',\n",
       " 'seriam',\n",
       " 'ser√≠amos',\n",
       " 'seu',\n",
       " 'seus',\n",
       " 's√≥',\n",
       " 'somos',\n",
       " 'sou',\n",
       " 'sua',\n",
       " 'suas',\n",
       " 'tamb√©m',\n",
       " 'te',\n",
       " 'tem',\n",
       " 't√©m',\n",
       " 'temos',\n",
       " 'tenha',\n",
       " 'tenham',\n",
       " 'tenhamos',\n",
       " 'tenho',\n",
       " 'ter√°',\n",
       " 'ter√£o',\n",
       " 'terei',\n",
       " 'teremos',\n",
       " 'teria',\n",
       " 'teriam',\n",
       " 'ter√≠amos',\n",
       " 'teu',\n",
       " 'teus',\n",
       " 'teve',\n",
       " 'tinha',\n",
       " 'tinham',\n",
       " 't√≠nhamos',\n",
       " 'tive',\n",
       " 'tivemos',\n",
       " 'tiver',\n",
       " 'tivera',\n",
       " 'tiveram',\n",
       " 'tiv√©ramos',\n",
       " 'tiverem',\n",
       " 'tivermos',\n",
       " 'tivesse',\n",
       " 'tivessem',\n",
       " 'tiv√©ssemos',\n",
       " 'tu',\n",
       " 'tua',\n",
       " 'tuas',\n",
       " 'um',\n",
       " 'uma',\n",
       " 'voc√™',\n",
       " 'voc√™s',\n",
       " 'vos']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ac725ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dba999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# üöÄ Fun√ß√£o que gera o regex dos termos da vaga\n",
    "# ===================================================\n",
    "def gerar_regex(texto):\n",
    "    if pd.isnull(texto):\n",
    "        return ''\n",
    "    \n",
    "    # üîß Pr√©-processamento\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'[\\n\\r\\t]', ' ', texto)\n",
    "    texto = re.sub(r'[\\.\\,\\;\\:\\(\\)\\[\\]\\{\\}\\!\\?]', ' ', texto)\n",
    "    \n",
    "    # ü™™ Extrai palavras\n",
    "    palavras = re.findall(r'\\b[a-zA-Z√Ä-√ø0-9\\-\\._\\+/]{2,}\\b', texto)\n",
    "    \n",
    "    # üéØ Filtra palavras relevantes\n",
    "    termos = [\n",
    "        palavra for palavra in palavras\n",
    "        if palavra not in stopwords and not palavra.isnumeric() and len(palavra) >= 4\n",
    "    ]\n",
    "    \n",
    "    termos_unicos = sorted(set(termos))\n",
    "    \n",
    "    # üî• Gera regex no formato (termo1|termo2|...)\n",
    "    if termos_unicos:\n",
    "        regex = r'(' + '|'.join(re.escape(termo) for termo in termos_unicos) + r')'\n",
    "    else:\n",
    "        regex = ''\n",
    "    \n",
    "    return regex\n",
    "\n",
    "# ===================================================\n",
    "# üöÄ Aplica a fun√ß√£o para gerar regex para cada linha\n",
    "# ===================================================\n",
    "df['regex_termos_vaga'] = df['perfil_vaga__competencia_tecnicas_e_comportamentais'].apply(gerar_regex)\n",
    "\n",
    "# ===================================================\n",
    "# üîç Verifica se os termos aparecem na coluna 'cv_pt'\n",
    "# ===================================================\n",
    "def buscar_termos(cv, regex):\n",
    "    if pd.isnull(cv) or regex == '':\n",
    "        return []\n",
    "    return re.findall(regex, cv.lower())\n",
    "\n",
    "# üîé Encontra os termos no CV com base no regex daquela linha ‚Äî sem duplicados\n",
    "df['termos_encontrados'] = df.apply(\n",
    "    lambda x: list(set(buscar_termos(x['cv_pt'], x['regex_termos_vaga']))), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# ‚úÖ Cria uma flag se encontrou algum termo\n",
    "df['possui_termo'] = df['termos_encontrados'].apply(\n",
    "    lambda x: 'Sim' if len(x) > 0 else 'N√£o'\n",
    ")\n",
    "\n",
    "# üî¢ Conta quantos termos aparecem por linha\n",
    "df['qtd_termos'] = df['termos_encontrados'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3d70997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.45      0.60      2803\n",
      "           1       0.63      0.96      0.76      2827\n",
      "\n",
      "    accuracy                           0.70      5630\n",
      "   macro avg       0.77      0.70      0.68      5630\n",
      "weighted avg       0.77      0.70      0.68      5630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================= üì• SELECIONAR COLUNAS =======================\n",
    "colunas = [\n",
    "    \"id_prospect\", \n",
    "    \"titulo\", \n",
    "    \"nome_candidato\", \n",
    "    \"codigo_candidato\", \n",
    "    \"situacao_candidado\",\n",
    "    \"infos_basicas__objetivo_profissional\",\n",
    "    \"informacoes_profissionais__area_atuacao\",\n",
    "    \"formacao_e_idiomas__nivel_academico\",\n",
    "    \"formacao_e_idiomas__nivel_ingles\",\n",
    "    \"formacao_e_idiomas__nivel_espanhol\",\n",
    "    \"cv_pt\", \n",
    "    \"perfil_vaga__competencia_tecnicas_e_comportamentais\",\n",
    "    \"perfil_vaga__nivel profissional\",\n",
    "    \"perfil_vaga__nivel_academico\", \n",
    "    \"regex_termos_vaga\", \n",
    "    \"termos_encontrados\", \n",
    "    \"possui_termo\", \n",
    "    \"qtd_termos\"\n",
    "]\n",
    "\n",
    "df = df[colunas].fillna('')\n",
    "\n",
    "# ======================= üè∑Ô∏è TARGET =======================\n",
    "status_positivo = [\n",
    "    'Encaminhado ao Requisitante',\n",
    "    'Contratado pela Decision',\n",
    "    'Contratado como Hunting',\n",
    "    'Aprovado',\n",
    "    'Entrevista T√©cnica',\n",
    "    'Entrevista com Cliente',\n",
    "    'Encaminhar Proposta',\n",
    "    'Proposta Aceita'\n",
    "]\n",
    "\n",
    "status_negativo = [\n",
    "    'N√£o Aprovado pelo RH',\n",
    "    'N√£o Aprovado pelo Cliente',\n",
    "    'N√£o Aprovado pelo Requisitante',\n",
    "    'Desistiu',\n",
    "    'Desistiu da Contrata√ß√£o',\n",
    "    'Sem interesse nesta vaga',\n",
    "    'Recusado'\n",
    "]\n",
    "\n",
    "df = df[df['situacao_candidado'].isin(status_positivo + status_negativo)]\n",
    "df['target'] = df['situacao_candidado'].apply(lambda x: 1 if x in status_positivo else 0)\n",
    "\n",
    "# ======================= üßπ FILTRO DE QUALIDADE =======================\n",
    "df['termos_encontrados'] = df['termos_encontrados'].apply(\n",
    "    lambda x: eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "df = df[~((df['target'] == 1) & (df['termos_encontrados'].apply(lambda x: len(x) == 0)))]\n",
    "\n",
    "# ======================= üî† SIMILARIDADE TF-IDF =======================\n",
    "vectorizer = TfidfVectorizer()\n",
    "corpus = df['perfil_vaga__competencia_tecnicas_e_comportamentais'].astype(str).tolist() + \\\n",
    "         df['cv_pt'].astype(str).tolist()\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "tfidf_vaga = tfidf_matrix[:len(df)]\n",
    "tfidf_cv = tfidf_matrix[len(df):]\n",
    "\n",
    "df['similaridade_cv_vaga'] = [\n",
    "    cosine_similarity(tfidf_cv[i], tfidf_vaga[i])[0][0] for i in range(len(df))\n",
    "]\n",
    "df['similaridade_cv_vaga'] = (df['similaridade_cv_vaga'] + 1) / 2  # Normalizar para 0-1\n",
    "\n",
    "# ======================= üìä DENSIDADE DE TERMOS =======================\n",
    "def calcular_match_percent(row):\n",
    "    try:\n",
    "        if pd.isna(row['regex_termos_vaga']) or row['regex_termos_vaga'] == '':\n",
    "            return 0\n",
    "        \n",
    "        # Verifica se j√° √© uma lista (evitando eval)\n",
    "        if isinstance(row['regex_termos_vaga'], list):\n",
    "            termos_vaga = row['regex_termos_vaga']\n",
    "        else:\n",
    "            # Remove caracteres problem√°ticos antes de fazer eval\n",
    "            termos_str = row['regex_termos_vaga'].strip()\n",
    "            if termos_str.startswith('(') and termos_str.endswith(')'):\n",
    "                termos_str = termos_str[1:-1]\n",
    "            termos_vaga = termos_str.split('|')\n",
    "        \n",
    "        total_termos = len(termos_vaga)\n",
    "        return row['qtd_termos'] / total_termos if total_termos > 0 else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "df['match_percent'] = df.apply(calcular_match_percent, axis=1)\n",
    "\n",
    "# ======================= üéì FEATURE - ADER√äNCIA ACAD√äMICA =======================\n",
    "def mapear_nivel_academico(nivel):\n",
    "    if pd.isna(nivel):\n",
    "        return 0\n",
    "    nivel = nivel.lower()\n",
    "    if \"doutorado\" in nivel: return 5\n",
    "    if \"mestrado\" in nivel: return 4\n",
    "    if \"p√≥s gradua√ß√£o\" in nivel or \"p√≥s-gradua√ß√£o\" in nivel: return 3\n",
    "    if \"ensino superior\" in nivel: return 2\n",
    "    if \"ensino t√©cnico\" in nivel: return 1.5\n",
    "    if \"ensino m√©dio\" in nivel: return 1\n",
    "    if \"ensino fundamental\" in nivel: return 0.5\n",
    "    return 0\n",
    "\n",
    "df['nivel_academico_candidato'] = df['formacao_e_idiomas__nivel_academico'].apply(mapear_nivel_academico)\n",
    "df['nivel_academico_vaga'] = df['perfil_vaga__nivel_academico'].apply(mapear_nivel_academico)\n",
    "\n",
    "df['aderencia_academica'] = df.apply(\n",
    "    lambda x: 1 if x['nivel_academico_candidato'] >= x['nivel_academico_vaga'] else 0.5 if x['nivel_academico_candidato'] >= x['nivel_academico_vaga'] - 1 else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ======================= üåê FEATURE - IDIOMAS =======================\n",
    "def mapear_nivel_idioma(nivel):\n",
    "    if pd.isna(nivel):\n",
    "        return 0\n",
    "    nivel = nivel.lower()\n",
    "    if nivel == 'nenhum': return 0\n",
    "    if nivel == 'b√°sico': return 1\n",
    "    if nivel == 'intermedi√°rio': return 2\n",
    "    if nivel == 'avan√ßado': return 3\n",
    "    if nivel == 'fluente': return 4\n",
    "    return 0\n",
    "\n",
    "nivel_ingles_vaga = 2  # Default intermedi√°rio\n",
    "nivel_espanhol_vaga = 1  # Default b√°sico\n",
    "\n",
    "df['nivel_ingles'] = df['formacao_e_idiomas__nivel_ingles'].apply(mapear_nivel_idioma)\n",
    "df['aderencia_ingles'] = df['nivel_ingles'].apply(\n",
    "    lambda x: 1 if x >= nivel_ingles_vaga else 0.5 if x >= nivel_ingles_vaga - 1 else 0\n",
    ")\n",
    "\n",
    "df['nivel_espanhol'] = df['formacao_e_idiomas__nivel_espanhol'].apply(mapear_nivel_idioma)\n",
    "df['aderencia_espanhol'] = df['nivel_espanhol'].apply(\n",
    "    lambda x: 1 if x >= nivel_espanhol_vaga else 0.5 if x >= nivel_espanhol_vaga - 1 else 0\n",
    ")\n",
    "\n",
    "# ======================= üíº FEATURE - N√çVEL PROFISSIONAL DA VAGA =======================\n",
    "mapa_nivel_profissional = {\n",
    "    'Aprendiz': 1, 'Trainee': 2, 'Auxiliar': 3, 'Assistente': 4,\n",
    "    'T√©cnico de N√≠vel M√©dio': 5, 'J√∫nior': 5.5, 'Analista': 6,\n",
    "    'Pleno': 7, 'Supervisor': 7, 'L√≠der': 7.5, 'S√™nior': 8,\n",
    "    'Especialista': 9, 'Coordenador': 9, 'Gerente': 10\n",
    "}\n",
    "\n",
    "df['nivel_profissional_vaga'] = df['perfil_vaga__nivel profissional'].map(mapa_nivel_profissional).fillna(0)\n",
    "df['nivel_profissional_norm'] = df['nivel_profissional_vaga'] / 10\n",
    "\n",
    "# ======================= üéØ FEATURES FINAIS =======================\n",
    "features = [\n",
    "    'match_percent',\n",
    "    'similaridade_cv_vaga',\n",
    "    'qtd_termos',\n",
    "    'aderencia_academica',\n",
    "    'aderencia_ingles',\n",
    "    'aderencia_espanhol',\n",
    "    'nivel_profissional_norm'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# ======================= üîß NORMALIZA√á√ÉO =======================\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ======================= ‚öñÔ∏è BALANCEAMENTO =======================\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# ======================= ü§ñ MODELO FINAL =======================\n",
    "modelo_final = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "modelo_final.fit(X_res, y_res)\n",
    "\n",
    "# Avalia√ß√£o do modelo\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, random_state=42\n",
    ")\n",
    "y_pred = modelo_final.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ======================= üíæ SALVAR MODELO =======================\n",
    "import joblib\n",
    "joblib.dump(modelo_final, 'modelo_rf_final.pkl')\n",
    "joblib.dump(scaler, 'scaler_final.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# ======================= üî• SCORE FINAL =======================\n",
    "df['prob_apto'] = modelo_final.predict_proba(X_scaled)[:, 1]\n",
    "df['score_final'] = (df['prob_apto'] * 0.3) + (df['match_percent'] * 0.4) + (df['similaridade_cv_vaga'] * 0.2) + (df['aderencia_academica'] * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60c43203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ======================= üì• SELECIONAR COLUNAS =======================\n",
    "# colunas = [\n",
    "#     \"id_prospect\", \n",
    "#     \"titulo\", \n",
    "#     \"nome_candidato\", \n",
    "#     \"codigo_candidato\", \n",
    "#     \"situacao_candidado\",\n",
    "#     \"infos_basicas__objetivo_profissional\",\n",
    "#     \"informacoes_profissionais__area_atuacao\",\n",
    "#     \"formacao_e_idiomas__nivel_academico\",\n",
    "#     \"formacao_e_idiomas__nivel_ingles\",\n",
    "#     \"formacao_e_idiomas__nivel_espanhol\",\n",
    "#     \"cv_pt\", \n",
    "#     \"perfil_vaga__competencia_tecnicas_e_comportamentais\",\n",
    "#     \"perfil_vaga__nivel profissional\",\n",
    "#     \"perfil_vaga__nivel_academico\", \n",
    "#     \"regex_termos_vaga\", \n",
    "#     \"termos_encontrados\", \n",
    "#     \"possui_termo\", \n",
    "#     \"qtd_termos\"\n",
    "# ]\n",
    "\n",
    "# df = df[colunas].fillna('')\n",
    "\n",
    "# # ======================= üè∑Ô∏è TARGET =======================\n",
    "# status_positivo = [\n",
    "#     'Encaminhado ao Requisitante',\n",
    "#     'Contratado pela Decision',\n",
    "#     'Contratado como Hunting',\n",
    "#     'Aprovado',\n",
    "#     'Entrevista T√©cnica',\n",
    "#     'Entrevista com Cliente',\n",
    "#     'Encaminhar Proposta',\n",
    "#     'Proposta Aceita'\n",
    "# ]\n",
    "\n",
    "# status_negativo = [\n",
    "#     'N√£o Aprovado pelo RH',\n",
    "#     'N√£o Aprovado pelo Cliente',\n",
    "#     'N√£o Aprovado pelo Requisitante',\n",
    "#     'Desistiu',\n",
    "#     'Desistiu da Contrata√ß√£o',\n",
    "#     'Sem interesse nesta vaga',\n",
    "#     'Recusado'\n",
    "# ]\n",
    "\n",
    "# df = df[df['situacao_candidado'].isin(status_positivo + status_negativo)]\n",
    "\n",
    "# df['target'] = df['situacao_candidado'].apply(\n",
    "#     lambda x: 1 if x in status_positivo else 0\n",
    "# )\n",
    "\n",
    "# # ======================= üßπ FILTRO DE QUALIDADE =======================\n",
    "# df['termos_encontrados'] = df['termos_encontrados'].apply(\n",
    "#     lambda x: eval(x) if isinstance(x, str) else x\n",
    "# )\n",
    "\n",
    "# df = df[~((df['target'] == 1) & (df['termos_encontrados'].apply(lambda x: len(x) == 0)))]\n",
    "\n",
    "# # ======================= üî† SIMILARIDADE TF-IDF =======================\n",
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "# corpus = df['perfil_vaga__competencia_tecnicas_e_comportamentais'].astype(str).tolist() + \\\n",
    "#          df['cv_pt'].astype(str).tolist()\n",
    "\n",
    "# tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# tfidf_vaga = tfidf_matrix[:len(df)]\n",
    "# tfidf_cv = tfidf_matrix[len(df):]\n",
    "\n",
    "# df['similaridade_cv_vaga'] = [\n",
    "#     cosine_similarity(tfidf_cv[i], tfidf_vaga[i])[0][0] for i in range(len(df))\n",
    "# ]\n",
    "\n",
    "# # ======================= üìä DENSIDADE DE TERMOS =======================\n",
    "# df['densidade_termos'] = df['qtd_termos'] / (df['cv_pt'].str.split().str.len() + 1)\n",
    "\n",
    "# # ======================= üéì FEATURE - ADER√äNCIA ACAD√äMICA =======================\n",
    "# def mapear_nivel_academico(nivel):\n",
    "#     if pd.isna(nivel):\n",
    "#         return 0\n",
    "#     nivel = nivel.lower()\n",
    "#     if \"doutorado\" in nivel:\n",
    "#         return 5\n",
    "#     if \"mestrado\" in nivel:\n",
    "#         return 4\n",
    "#     if \"p√≥s gradua√ß√£o\" in nivel or \"p√≥s-gradua√ß√£o\" in nivel:\n",
    "#         return 3\n",
    "#     if \"ensino superior\" in nivel:\n",
    "#         return 2\n",
    "#     if \"ensino t√©cnico\" in nivel:\n",
    "#         return 1.5\n",
    "#     if \"ensino m√©dio\" in nivel:\n",
    "#         return 1\n",
    "#     if \"ensino fundamental\" in nivel:\n",
    "#         return 0.5\n",
    "#     return 0\n",
    "\n",
    "# df['nivel_academico_candidato'] = df['formacao_e_idiomas__nivel_academico'].apply(mapear_nivel_academico)\n",
    "# df['nivel_academico_vaga'] = df['perfil_vaga__nivel_academico'].apply(mapear_nivel_academico)\n",
    "\n",
    "# df['aderencia_academica'] = df.apply(\n",
    "#     lambda x: 1 if x['nivel_academico_candidato'] >= x['nivel_academico_vaga'] else 0, axis=1\n",
    "# )\n",
    "\n",
    "# # ======================= üåê FEATURE - IDIOMAS =======================\n",
    "# def mapear_nivel_idioma(nivel):\n",
    "#     if pd.isna(nivel):\n",
    "#         return 0\n",
    "#     nivel = nivel.lower()\n",
    "#     if nivel == 'nenhum':\n",
    "#         return 0\n",
    "#     if nivel == 'b√°sico':\n",
    "#         return 1\n",
    "#     if nivel == 'intermedi√°rio':\n",
    "#         return 2\n",
    "#     if nivel == 'avan√ßado':\n",
    "#         return 3\n",
    "#     if nivel == 'fluente':\n",
    "#         return 4\n",
    "#     return 0\n",
    "\n",
    "# df['nivel_ingles'] = df['formacao_e_idiomas__nivel_ingles'].apply(mapear_nivel_idioma)\n",
    "# df['nivel_espanhol'] = df['formacao_e_idiomas__nivel_espanhol'].apply(mapear_nivel_idioma)\n",
    "# df['media_idiomas'] = (df['nivel_ingles'] + df['nivel_espanhol']) / 2\n",
    "\n",
    "# # ======================= üíº FEATURE - N√çVEL PROFISSIONAL DA VAGA =======================\n",
    "# mapa_nivel_profissional = {\n",
    "#     'Aprendiz': 1,\n",
    "#     'Trainee': 2,\n",
    "#     'Auxiliar': 3,\n",
    "#     'Assistente': 4,\n",
    "#     'T√©cnico de N√≠vel M√©dio': 5,\n",
    "#     'J√∫nior': 5.5,\n",
    "#     'Analista': 6,\n",
    "#     'Pleno': 7,\n",
    "#     'Supervisor': 7,\n",
    "#     'L√≠der': 7.5,\n",
    "#     'S√™nior': 8,\n",
    "#     'Especialista': 9,\n",
    "#     'Coordenador': 9,\n",
    "#     'Gerente': 10\n",
    "# }\n",
    "\n",
    "# df['nivel_profissional_vaga'] = df['perfil_vaga__nivel profissional'].map(mapa_nivel_profissional).fillna(0)\n",
    "\n",
    "# # ======================= üéØ FEATURES FINAIS =======================\n",
    "# features = [\n",
    "#     'qtd_termos',\n",
    "#     'similaridade_cv_vaga',\n",
    "#     'densidade_termos',\n",
    "#     'aderencia_academica',\n",
    "#     'nivel_ingles',\n",
    "#     'nivel_espanhol',\n",
    "#     'nivel_profissional_vaga'\n",
    "# ]\n",
    "\n",
    "# X = df[features]\n",
    "# y = df['target']\n",
    "\n",
    "# # ======================= üîß NORMALIZA√á√ÉO =======================\n",
    "# scaler = MinMaxScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # ======================= ‚öñÔ∏è BALANCEAMENTO =======================\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_res, y_res = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# # ======================= üöÄ SPLIT =======================\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_res, y_res, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# # ======================= ü§ñ MODELOS =======================\n",
    "# modelos = {\n",
    "#     'RandomForest': RandomForestClassifier(random_state=42),\n",
    "#     'XGBoost': XGBClassifier(random_state=42, verbosity=0),\n",
    "#     'LightGBM': LGBMClassifier(random_state=42),\n",
    "#     'LogisticRegression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "# }\n",
    "\n",
    "# for nome, modelo in modelos.items():\n",
    "#     modelo.fit(X_train, y_train)\n",
    "#     y_pred = modelo.predict(X_test)\n",
    "#     print(f\"\\nüîç Modelo: {nome}\")\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # ======================= ‚úÖ MODELO FINAL =======================\n",
    "# modelo_final = RandomForestClassifier(random_state=42)\n",
    "# modelo_final.fit(X_res, y_res)\n",
    "\n",
    "# # ======================= üî• NOVO SCORE FINAL =======================\n",
    "# df['prob_apto'] = modelo_final.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "# # Normaliza√ß√£o manual de vari√°veis complementares\n",
    "# df['qtd_termos_norm'] = df['qtd_termos'] / df['qtd_termos'].max()\n",
    "# df['densidade_termos_norm'] = df['densidade_termos'] / df['densidade_termos'].max()\n",
    "# df['nivel_profissional_norm'] = df['nivel_profissional_vaga'] / 10\n",
    "# df['media_idiomas_norm'] = df['media_idiomas'] / 4\n",
    "\n",
    "# # Score mais balanceado e robusto\n",
    "# df['score_final'] = (\n",
    "#     (df['prob_apto'] * 0.5) +  \n",
    "#     (df['similaridade_cv_vaga'] * 0.2) +  \n",
    "#     (df['aderencia_academica'] * 0.1) +  \n",
    "#     (df['media_idiomas_norm'] * 0.05) +  \n",
    "#     (df['nivel_profissional_norm'] * 0.05) +  \n",
    "#     (df['qtd_termos_norm'] * 0.05) +  \n",
    "#     (df['densidade_termos_norm'] * 0.05)  \n",
    "# )\n",
    "\n",
    "# # ======================= üèÜ TOP CANDIDATOS =======================\n",
    "# top_candidatos = df.sort_values('score_final', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48ca1633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Distribui√ß√£o dos candidatos por status:\n",
      "\n",
      "status_candidato\n",
      "‚úÖ Apto - Shortlist       19046\n",
      "‚ùå N√£o Apto                2675\n",
      "üü® Potencial - Triagem     1360\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ======================= üî• CLASSIFICA√á√ÉO COM 2 THRESHOLDS =======================\n",
    "\n",
    "# üî• Definir os thresholds\n",
    "threshold_triagem = 0.4   # Para triagem inicial\n",
    "threshold_shortlist = 0.5  # Para shortlist e encaminhamento final\n",
    "\n",
    "# üìä Classificar os candidatos em faixas\n",
    "def classificar_candidato(prob):\n",
    "    if prob >= threshold_shortlist:\n",
    "        return '‚úÖ Apto - Shortlist'\n",
    "    elif prob >= threshold_triagem:\n",
    "        return 'üü® Potencial - Triagem'\n",
    "    else:\n",
    "        return '‚ùå N√£o Apto'\n",
    "\n",
    "df['status_candidato'] = df['prob_apto'].apply(classificar_candidato)\n",
    "\n",
    "# ======================= üèÜ GERAR RANKING FINAL =======================\n",
    "\n",
    "# üìà Organizar ranking\n",
    "df_rank = df.sort_values('score_final', ascending=False)\n",
    "\n",
    "# ======================= üìä VISUALIZAR QUANTITATIVO =======================\n",
    "\n",
    "print(\"\\nüìä Distribui√ß√£o dos candidatos por status:\\n\")\n",
    "print(df_rank['status_candidato'].value_counts())\n",
    "\n",
    "# ======================= üîç FILTROS SEPARADOS =======================\n",
    "\n",
    "# üèÜ Shortlist\n",
    "shortlist = df_rank[df_rank['status_candidato'] == '‚úÖ Apto - Shortlist']\n",
    "\n",
    "# üü® Triagem\n",
    "triagem = df_rank[df_rank['status_candidato'] == 'üü® Potencial - Triagem']\n",
    "\n",
    "# ‚ùå N√£o Apto\n",
    "nao_apto = df_rank[df_rank['status_candidato'] == '‚ùå N√£o Apto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b51bfe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Salvar o modelo treinado\n",
    "# joblib.dump(modelo_final, 'modelo_rf.pkl')\n",
    "\n",
    "# # Salvar o scaler que voc√™ usou\n",
    "# joblib.dump(scaler, 'scaler.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
